

============================== 2022-09-29 16:38:22.751780 | b02b7e3a-4729-4f5a-8270-71bb996dad16 ==============================
[0m16:38:22.751791 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:38:22.752417 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_name': 'my_dbt_demo', 'skip_profile_setup': False, 'which': 'init', 'indirect_selection': 'eager'}
[0m16:38:22.752666 [debug] [MainThread]: Tracking: tracking
[0m16:38:22.777203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bbbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bbbc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bbbd90>]}
[0m16:38:22.779910 [info ] [MainThread]: Creating dbt configuration folder at /Users/tcsilva/.dbt
[0m16:38:22.782624 [debug] [MainThread]: Flushing usage events


============================== 2022-09-29 16:41:00.830020 | d42bbd2f-17a3-4330-a8fa-ad2e3051d200 ==============================
[0m16:41:00.830038 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:41:00.830673 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_name': 'my_dbt_demo', 'skip_profile_setup': False, 'which': 'init', 'indirect_selection': 'eager'}
[0m16:41:00.830849 [debug] [MainThread]: Tracking: tracking
[0m16:41:00.852548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b72d280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b72d400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b72d3a0>]}
[0m16:41:00.855591 [debug] [MainThread]: Starter project path: /Users/tcsilva/.virtualenvs/dbt/lib/python3.9/site-packages/dbt/include/starter_project
[0m16:46:14.501383 [info ] [MainThread]: Profile my_dbt_demo written to /Users/tcsilva/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m16:46:14.502333 [info ] [MainThread]: 
Your new dbt project "my_dbt_demo" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m16:46:14.502786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db3940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db3430>]}
[0m16:46:14.503192 [debug] [MainThread]: Flushing usage events


============================== 2022-09-29 16:46:37.475024 | 2f7b6845-462a-4cd3-9182-26a156643cab ==============================
[0m16:46:37.475037 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:46:37.475393 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m16:46:37.475592 [debug] [MainThread]: Tracking: tracking
[0m16:46:37.495988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052a5760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101c3d8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052a5910>]}
[0m16:46:38.232235 [debug] [MainThread]: Executing "git --help"
[0m16:46:38.250657 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:46:38.251598 [debug] [MainThread]: STDERR: "b''"
[0m16:46:38.262844 [debug] [MainThread]: Acquiring new databricks connection "debug"
[0m16:46:38.265031 [debug] [MainThread]: Using databricks connection "debug"
[0m16:46:38.265332 [debug] [MainThread]: On debug: select 1 as id
[0m16:46:38.265571 [debug] [MainThread]: Opening a new connection, currently in state init


============================== 2022-09-29 16:47:21.650720 | 985ad19e-7f5b-485e-92ea-062b43588bd0 ==============================
[0m16:47:21.650730 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:47:21.651274 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_name': 'my_dbt_demo', 'skip_profile_setup': False, 'which': 'init', 'indirect_selection': 'eager'}
[0m16:47:21.651503 [debug] [MainThread]: Tracking: tracking
[0m16:47:21.667779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb93a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb93340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c51a8e0>]}
[0m16:47:21.672124 [info ] [MainThread]: A project called my_dbt_demo already exists here.
[0m16:47:21.672795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb93d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c51a8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb90100>]}
[0m16:47:21.673058 [debug] [MainThread]: Flushing usage events


============================== 2022-09-29 16:49:55.346368 | f946d4fd-1080-4a13-9602-6ed8c0545050 ==============================
[0m16:49:55.346382 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:49:55.362995 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_name': 'my_dbt_demo', 'skip_profile_setup': False, 'which': 'init', 'indirect_selection': 'eager'}
[0m16:49:55.363429 [debug] [MainThread]: Tracking: tracking
[0m16:49:55.385286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112493880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee1b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112493f70>]}
[0m16:49:55.388723 [debug] [MainThread]: Starter project path: /Users/tcsilva/.virtualenvs/dbt/lib/python3.9/site-packages/dbt/include/starter_project
[0m16:51:04.920893 [info ] [MainThread]: Profile my_dbt_demo written to /Users/tcsilva/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m16:51:04.921786 [info ] [MainThread]: 
Your new dbt project "my_dbt_demo" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m16:51:04.922197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112480af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112480ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112480c40>]}
[0m16:51:04.922472 [debug] [MainThread]: Flushing usage events


============================== 2022-09-29 16:51:26.258884 | 29ee3b76-1aaa-45f9-b748-a424c591e5cb ==============================
[0m16:51:26.258900 [info ] [MainThread]: Running with dbt=1.2.1
[0m16:51:26.259513 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m16:51:26.259734 [debug] [MainThread]: Tracking: tracking
[0m16:51:26.275724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064c7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d8cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d8850>]}
[0m16:51:27.025701 [debug] [MainThread]: Executing "git --help"
[0m16:51:27.038831 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:51:27.039998 [debug] [MainThread]: STDERR: "b''"
[0m16:51:27.047584 [debug] [MainThread]: Acquiring new databricks connection "debug"
[0m16:51:27.050441 [debug] [MainThread]: Using databricks connection "debug"
[0m16:51:27.051180 [debug] [MainThread]: On debug: select 1 as id
[0m16:51:27.051690 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:51:28.754563 [debug] [MainThread]: SQL status: OK in 1.7 seconds
[0m16:51:28.757051 [debug] [MainThread]: On debug: Close
[0m16:51:29.338292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b50940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b50790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116b701c0>]}
[0m16:51:29.339231 [debug] [MainThread]: Flushing usage events
[0m16:51:29.963965 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-10-13 14:35:04.855819 | 966b2ba9-55bc-451e-b298-97d40dee042f ==============================
[0m14:35:04.855875 [info ] [MainThread]: Running with dbt=1.2.1
[0m14:35:04.856290 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m14:35:04.856543 [debug] [MainThread]: Tracking: tracking
[0m14:35:04.878416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c57cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c57df0>]}
[0m14:35:04.881926 [debug] [MainThread]: Set downloads directory='/var/folders/w0/s3mbsxd16_11s_lm9ktylhbh0000gp/T/dbt-downloads-8bn1effn'
[0m14:35:04.883296 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:taticorrea-unico/dbt-shared.git a94bbf9cd452d751ed6abe35e86d7cd7"
[0m14:35:07.113611 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:07.114943 [debug] [MainThread]: STDERR: "b"Cloning into 'a94bbf9cd452d751ed6abe35e86d7cd7'...\n""
[0m14:35:07.115654 [debug] [MainThread]: Pulling new dependency a94bbf9cd452d751ed6abe35e86d7cd7.
[0m14:35:07.115824 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:07.124421 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:07.125716 [debug] [MainThread]: STDERR: "b''"
[0m14:35:07.126063 [debug] [MainThread]:   Checking out revision main.
[0m14:35:07.126270 [debug] [MainThread]: Executing "git remote set-branches origin main"
[0m14:35:07.136180 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:07.137055 [debug] [MainThread]: STDERR: "b''"
[0m14:35:07.137344 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags main"
[0m14:35:09.209000 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:09.210569 [debug] [MainThread]: STDERR: "b'From github.com:taticorrea-unico/dbt-shared\n * branch            main       -> FETCH_HEAD\n'"
[0m14:35:09.211042 [debug] [MainThread]: Executing "git tag --list"
[0m14:35:09.221542 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:09.222619 [debug] [MainThread]: STDERR: "b''"
[0m14:35:09.222970 [debug] [MainThread]: Executing "git reset --hard origin/main"
[0m14:35:09.238489 [debug] [MainThread]: STDOUT: "b'HEAD is now at a31cf3a ajustes\n'"
[0m14:35:09.239641 [debug] [MainThread]: STDERR: "b''"
[0m14:35:09.239925 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:09.249086 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:09.250268 [debug] [MainThread]: STDERR: "b''"
[0m14:35:09.250601 [debug] [MainThread]:   Checked out at a31cf3a.
[0m14:35:09.251040 [warn ] [MainThread]: [33mWARNING: The git package "git@github.com:taticorrea-unico/dbt-shared.git" 
	is pinned to the "main" branch.
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m14:35:09.261932 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:taticorrea-unico/dbt-shared.git a94bbf9cd452d751ed6abe35e86d7cd7"
[0m14:35:09.270670 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:09.272011 [debug] [MainThread]: STDERR: "b"fatal: destination path 'a94bbf9cd452d751ed6abe35e86d7cd7' already exists and is not an empty directory.\n""
[0m14:35:09.272413 [debug] [MainThread]: command return code=128
[0m14:35:09.273823 [debug] [MainThread]: Updating existing dependency a94bbf9cd452d751ed6abe35e86d7cd7.
[0m14:35:09.274030 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:09.283245 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:09.284318 [debug] [MainThread]: STDERR: "b''"
[0m14:35:09.284638 [debug] [MainThread]:   Checking out revision main.
[0m14:35:09.284852 [debug] [MainThread]: Executing "git remote set-branches origin main"
[0m14:35:09.295019 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:09.296215 [debug] [MainThread]: STDERR: "b''"
[0m14:35:09.296430 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags main"
[0m14:35:11.404697 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:11.406025 [debug] [MainThread]: STDERR: "b'From github.com:taticorrea-unico/dbt-shared\n * branch            main       -> FETCH_HEAD\n'"
[0m14:35:11.406361 [debug] [MainThread]: Executing "git tag --list"
[0m14:35:11.416974 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:11.418144 [debug] [MainThread]: STDERR: "b''"
[0m14:35:11.418483 [debug] [MainThread]: Executing "git reset --hard origin/main"
[0m14:35:11.429652 [debug] [MainThread]: STDOUT: "b'HEAD is now at a31cf3a ajustes\n'"
[0m14:35:11.430697 [debug] [MainThread]: STDERR: "b''"
[0m14:35:11.431025 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:11.440330 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:11.441745 [debug] [MainThread]: STDERR: "b''"
[0m14:35:11.442185 [debug] [MainThread]: Already at a31cf3a, nothing to do.
[0m14:35:11.442550 [warn ] [MainThread]: [33mWARNING: The git package "git@github.com:taticorrea-unico/dbt-shared.git" 
	is pinned to the "main" branch.
	This can introduce breaking changes into your project without warning!

See https://docs.getdbt.com/docs/package-management#section-specifying-package-versions[0m
[0m14:35:11.454438 [info ] [MainThread]: Installing git@github.com:taticorrea-unico/dbt-shared.git
[0m14:35:11.455162 [debug] [MainThread]: Executing "git clone --depth 1 git@github.com:taticorrea-unico/dbt-shared.git a94bbf9cd452d751ed6abe35e86d7cd7"
[0m14:35:11.466480 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:11.467873 [debug] [MainThread]: STDERR: "b"fatal: destination path 'a94bbf9cd452d751ed6abe35e86d7cd7' already exists and is not an empty directory.\n""
[0m14:35:11.468232 [debug] [MainThread]: command return code=128
[0m14:35:11.469476 [debug] [MainThread]: Updating existing dependency a94bbf9cd452d751ed6abe35e86d7cd7.
[0m14:35:11.469903 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:11.479460 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:11.480666 [debug] [MainThread]: STDERR: "b''"
[0m14:35:11.481251 [debug] [MainThread]:   Checking out revision main.
[0m14:35:11.481541 [debug] [MainThread]: Executing "git remote set-branches origin main"
[0m14:35:11.492453 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:11.493590 [debug] [MainThread]: STDERR: "b''"
[0m14:35:11.493832 [debug] [MainThread]: Executing "git fetch origin --depth 1 --tags main"
[0m14:35:13.523790 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:13.525568 [debug] [MainThread]: STDERR: "b'From github.com:taticorrea-unico/dbt-shared\n * branch            main       -> FETCH_HEAD\n'"
[0m14:35:13.526029 [debug] [MainThread]: Executing "git tag --list"
[0m14:35:13.537737 [debug] [MainThread]: STDOUT: "b''"
[0m14:35:13.538883 [debug] [MainThread]: STDERR: "b''"
[0m14:35:13.539398 [debug] [MainThread]: Executing "git reset --hard origin/main"
[0m14:35:13.554145 [debug] [MainThread]: STDOUT: "b'HEAD is now at a31cf3a ajustes\n'"
[0m14:35:13.555554 [debug] [MainThread]: STDERR: "b''"
[0m14:35:13.556041 [debug] [MainThread]: Executing "git rev-parse HEAD"
[0m14:35:13.565362 [debug] [MainThread]: STDOUT: "b'a31cf3a5878ecccbb7deaf5793ca7b5ea8a4ed01\n'"
[0m14:35:13.566688 [debug] [MainThread]: STDERR: "b''"
[0m14:35:13.567036 [debug] [MainThread]: Already at a31cf3a, nothing to do.
[0m14:35:13.567518 [info ] [MainThread]:   Installed from revision main
[0m14:35:13.568636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '966b2ba9-55bc-451e-b298-97d40dee042f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c82280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c82af0>]}
[0m14:35:13.570161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c57cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c82970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c82e80>]}
[0m14:35:13.570556 [debug] [MainThread]: Flushing usage events


============================== 2022-10-19 20:20:33.764633 | 72008ff1-d131-4af5-94fb-2a2a1b9e660b ==============================
[0m20:20:33.764793 [info ] [MainThread]: Running with dbt=1.2.1
[0m20:20:33.768857 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/tcsilva/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m20:20:33.769869 [debug] [MainThread]: Tracking: tracking
[0m20:20:33.838846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165ea040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165ea580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165ea100>]}
[0m20:20:33.929646 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
[0m20:20:33.930414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '72008ff1-d131-4af5-94fb-2a2a1b9e660b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116629cd0>]}
[0m20:20:34.138619 [debug] [MainThread]: Parsing macros/statement.sql
[0m20:20:34.153494 [debug] [MainThread]: Parsing macros/catalog.sql
[0m20:20:34.161104 [debug] [MainThread]: Parsing macros/adapters.sql
[0m20:20:34.278821 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m20:20:34.316771 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m20:20:34.318503 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m20:20:34.332282 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m20:20:34.394099 [debug] [MainThread]: Parsing macros/materializations/incremental/incremental.sql
[0m20:20:34.477661 [debug] [MainThread]: Parsing macros/adapters.sql
[0m20:20:34.577457 [debug] [MainThread]: Parsing macros/apply_grants.sql
[0m20:20:34.589959 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m20:20:34.614871 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m20:20:34.616257 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m20:20:34.623350 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m20:20:34.672160 [debug] [MainThread]: Parsing macros/materializations/incremental/validate.sql
[0m20:20:34.680018 [debug] [MainThread]: Parsing macros/materializations/incremental/strategies.sql
[0m20:20:34.694172 [debug] [MainThread]: Parsing macros/materializations/incremental/incremental.sql
[0m20:20:34.714871 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m20:20:34.715850 [debug] [MainThread]: Parsing macros/utils/assert_not_null.sql
[0m20:20:34.717602 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m20:20:34.726961 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m20:20:34.732015 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m20:20:34.758784 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m20:20:34.759681 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m20:20:34.761203 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m20:20:34.764038 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m20:20:34.774177 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m20:20:34.777594 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m20:20:34.781868 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m20:20:34.817227 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m20:20:34.837046 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m20:20:34.865436 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m20:20:34.878842 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m20:20:34.883323 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m20:20:34.887664 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m20:20:34.895675 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m20:20:34.931923 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m20:20:34.934659 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m20:20:34.949621 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m20:20:34.979232 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m20:20:34.990454 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m20:20:35.000114 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m20:20:35.012367 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m20:20:35.015318 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m20:20:35.020537 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m20:20:35.027918 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m20:20:35.041680 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m20:20:35.080492 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m20:20:35.083262 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m20:20:35.089021 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m20:20:35.091875 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m20:20:35.093661 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m20:20:35.095098 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m20:20:35.096921 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m20:20:35.100870 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m20:20:35.115206 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m20:20:35.131187 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m20:20:35.132996 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m20:20:35.137043 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m20:20:35.138958 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m20:20:35.142452 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m20:20:35.145471 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m20:20:35.148616 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m20:20:35.153019 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m20:20:35.157583 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m20:20:35.165109 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m20:20:35.169450 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m20:20:35.173125 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m20:20:35.175785 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m20:20:35.177342 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m20:20:35.178641 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m20:20:35.180137 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m20:20:35.181379 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m20:20:35.191047 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m20:20:35.193865 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m20:20:35.203505 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m20:20:35.213613 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m20:20:35.219782 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m20:20:35.229520 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m20:20:35.240853 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m20:20:35.292623 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m20:20:35.305435 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m20:20:35.360427 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m20:20:35.371873 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m20:20:35.393260 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m20:20:35.425669 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m20:20:35.431359 [debug] [MainThread]: Parsing macros/new_macro.sql
[0m20:20:36.347873 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:20:36.382724 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m20:20:36.442649 [debug] [MainThread]: 1699: static parser successfully parsed example/my_terceiro_dbt_model.sql
[0m20:20:36.659236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '72008ff1-d131-4af5-94fb-2a2a1b9e660b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1166e2880>]}
[0m20:20:36.679377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72008ff1-d131-4af5-94fb-2a2a1b9e660b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165eac70>]}
[0m20:20:36.680176 [info ] [MainThread]: Found 3 models, 6 tests, 0 snapshots, 0 analyses, 322 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m20:20:36.681467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72008ff1-d131-4af5-94fb-2a2a1b9e660b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1167913a0>]}
[0m20:20:36.685740 [info ] [MainThread]: 
[0m20:20:36.687204 [debug] [MainThread]: Acquiring new databricks connection "master"
[0m20:20:36.688525 [debug] [ThreadPool]: Acquiring new databricks connection "list_None_schema_dbt"
[0m20:20:36.717423 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m20:20:36.717927 [debug] [ThreadPool]: Using databricks connection "list_None_schema_dbt"
[0m20:20:36.718418 [debug] [ThreadPool]: On list_None_schema_dbt: /* {"app": "dbt", "dbt_version": "1.2.1", "dbt_databricks_version": "1.2.3", "databricks_sql_connector_version": "2.0.5", "profile_name": "dbt_demo", "target_name": "dev", "connection_name": "list_None_schema_dbt"} */
show table extended in schema_dbt like '*'
  
[0m20:20:36.718684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:20:38.848980 [debug] [ThreadPool]: Databricks adapter: Error while running:
/* {"app": "dbt", "dbt_version": "1.2.1", "dbt_databricks_version": "1.2.3", "databricks_sql_connector_version": "2.0.5", "profile_name": "dbt_demo", "target_name": "dev", "connection_name": "list_None_schema_dbt"} */
show table extended in schema_dbt like '*'
  
[0m20:20:38.849586 [debug] [ThreadPool]: Databricks adapter: <class 'databricks.sql.exc.ServerOperationError'>: Database 'schema_dbt' not found
[0m20:20:38.850284 [debug] [ThreadPool]: Databricks adapter: diagnostic-info: org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.catalyst.analysis.NoSuchDatabaseException: Database 'schema_dbt' not found
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:47)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:435)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:257)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:123)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:48)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:52)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:235)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:220)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:269)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchDatabaseException: Database 'schema_dbt' not found
	at org.apache.spark.sql.catalyst.catalog.SessionCatalogImpl.requireDbExists(SessionCatalog.scala:647)
	at org.apache.spark.sql.catalyst.catalog.SessionCatalogImpl.doListTables(SessionCatalog.scala:1506)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.doListTables(ManagedCatalogSessionCatalog.scala:1180)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.doListTables(ManagedCatalogSessionCatalog.scala:1290)
	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.listTables(SessionCatalog.scala:286)
	at org.apache.spark.sql.execution.command.ShowTablesCommand.$anonfun$run$46(tables.scala:919)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.execution.command.ShowTablesCommand.run(tables.scala:919)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:80)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:78)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:89)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$8(SQLExecution.scala:239)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:386)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:186)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:968)
	at org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:141)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:336)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:160)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:156)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:575)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:167)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:575)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:268)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:264)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:551)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:156)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:324)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:156)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:141)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:132)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:186)
	at org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:191)
	at org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:188)
	at org.apache.spark.sql.execution.QueryExecution.assertOptimized(QueryExecution.scala:206)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:225)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:222)
	at org.apache.spark.sql.execution.QueryExecution.assertExecutedPlanPrepared(QueryExecution.scala:240)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$compileQuery$2(SparkExecuteStatementOperation.scala:351)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:968)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$compileQuery$1(SparkExecuteStatementOperation.scala:334)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:327)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.compileQuery(SparkExecuteStatementOperation.scala:334)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:390)
	... 16 more

[0m20:20:38.850832 [debug] [ThreadPool]: Databricks adapter: operation-id: b'\x86\xbf$?\xee\xb3H\x97\x84\x90(\xea\xa8\xd7\xad\x00'
[0m20:20:38.851509 [debug] [ThreadPool]: Databricks adapter: Error while running:
macro list_relations_without_caching
[0m20:20:38.852162 [debug] [ThreadPool]: Databricks adapter: Runtime Error
  Database 'schema_dbt' not found
[0m20:20:38.853100 [debug] [ThreadPool]: On list_None_schema_dbt: ROLLBACK
[0m20:20:38.853553 [debug] [ThreadPool]: Databricks adapter: NotImplemented: rollback
[0m20:20:38.853976 [debug] [ThreadPool]: On list_None_schema_dbt: Close
[0m20:20:39.308430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72008ff1-d131-4af5-94fb-2a2a1b9e660b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116813c10>]}
[0m20:20:39.310232 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:20:39.312035 [info ] [MainThread]: 
[0m20:20:39.325694 [debug] [Thread-1  ]: Began running node model.dbt_demo.my_first_dbt_model
[0m20:20:39.326797 [debug] [Thread-1  ]: Acquiring new databricks connection "model.dbt_demo.my_first_dbt_model"
[0m20:20:39.327263 [debug] [Thread-1  ]: Began compiling node model.dbt_demo.my_first_dbt_model
[0m20:20:39.327825 [debug] [Thread-1  ]: Compiling model.dbt_demo.my_first_dbt_model
[0m20:20:39.335712 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_demo.my_first_dbt_model"
[0m20:20:39.337563 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.339083 [debug] [Thread-1  ]: Began executing node model.dbt_demo.my_first_dbt_model
[0m20:20:39.339802 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.341206 [debug] [Thread-1  ]: Finished running node model.dbt_demo.my_first_dbt_model
[0m20:20:39.342005 [debug] [Thread-1  ]: Began running node model.dbt_shared.my_terceiro_dbt_model
[0m20:20:39.342975 [debug] [Thread-1  ]: Acquiring new databricks connection "model.dbt_shared.my_terceiro_dbt_model"
[0m20:20:39.344243 [debug] [Thread-1  ]: Began compiling node model.dbt_shared.my_terceiro_dbt_model
[0m20:20:39.344790 [debug] [Thread-1  ]: Compiling model.dbt_shared.my_terceiro_dbt_model
[0m20:20:39.356536 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_shared.my_terceiro_dbt_model"
[0m20:20:39.357995 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.358523 [debug] [Thread-1  ]: Began executing node model.dbt_shared.my_terceiro_dbt_model
[0m20:20:39.359053 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.361857 [debug] [Thread-1  ]: Finished running node model.dbt_shared.my_terceiro_dbt_model
[0m20:20:39.362942 [debug] [Thread-1  ]: Began running node model.dbt_demo.my_second_dbt_model
[0m20:20:39.366647 [debug] [Thread-1  ]: Acquiring new databricks connection "model.dbt_demo.my_second_dbt_model"
[0m20:20:39.367196 [debug] [Thread-1  ]: Began compiling node model.dbt_demo.my_second_dbt_model
[0m20:20:39.367652 [debug] [Thread-1  ]: Compiling model.dbt_demo.my_second_dbt_model
[0m20:20:39.376239 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_demo.my_second_dbt_model"
[0m20:20:39.377298 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.377825 [debug] [Thread-1  ]: Began executing node model.dbt_demo.my_second_dbt_model
[0m20:20:39.378277 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.379413 [debug] [Thread-1  ]: Finished running node model.dbt_demo.my_second_dbt_model
[0m20:20:39.380103 [debug] [Thread-1  ]: Began running node test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:20:39.381529 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710"
[0m20:20:39.382202 [debug] [Thread-1  ]: Began compiling node test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:20:39.382840 [debug] [Thread-1  ]: Compiling test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:20:39.429834 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710"
[0m20:20:39.432191 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.433097 [debug] [Thread-1  ]: Began executing node test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:20:39.433468 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.434456 [debug] [Thread-1  ]: Finished running node test.dbt_demo.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:20:39.434988 [debug] [Thread-1  ]: Began running node test.dbt_demo.unique_my_first_dbt_model_id.16e066b321
[0m20:20:39.435917 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_demo.unique_my_first_dbt_model_id.16e066b321"
[0m20:20:39.436514 [debug] [Thread-1  ]: Began compiling node test.dbt_demo.unique_my_first_dbt_model_id.16e066b321
[0m20:20:39.437113 [debug] [Thread-1  ]: Compiling test.dbt_demo.unique_my_first_dbt_model_id.16e066b321
[0m20:20:39.462664 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_demo.unique_my_first_dbt_model_id.16e066b321"
[0m20:20:39.464661 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.465270 [debug] [Thread-1  ]: Began executing node test.dbt_demo.unique_my_first_dbt_model_id.16e066b321
[0m20:20:39.465931 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.467721 [debug] [Thread-1  ]: Finished running node test.dbt_demo.unique_my_first_dbt_model_id.16e066b321
[0m20:20:39.469231 [debug] [Thread-1  ]: Began running node test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3
[0m20:20:39.473545 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3"
[0m20:20:39.474180 [debug] [Thread-1  ]: Began compiling node test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3
[0m20:20:39.474692 [debug] [Thread-1  ]: Compiling test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3
[0m20:20:39.490071 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3"
[0m20:20:39.491451 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.492196 [debug] [Thread-1  ]: Began executing node test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3
[0m20:20:39.492977 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.495607 [debug] [Thread-1  ]: Finished running node test.dbt_shared.not_null_my_terceiro_dbt_model_id.12d773ddb3
[0m20:20:39.496336 [debug] [Thread-1  ]: Began running node test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a
[0m20:20:39.497683 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a"
[0m20:20:39.498442 [debug] [Thread-1  ]: Began compiling node test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a
[0m20:20:39.499305 [debug] [Thread-1  ]: Compiling test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a
[0m20:20:39.514499 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a"
[0m20:20:39.516608 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.517228 [debug] [Thread-1  ]: Began executing node test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a
[0m20:20:39.517842 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.519070 [debug] [Thread-1  ]: Finished running node test.dbt_shared.unique_my_terceiro_dbt_model_id.6d5fd4e39a
[0m20:20:39.520116 [debug] [Thread-1  ]: Began running node test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778
[0m20:20:39.521083 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778"
[0m20:20:39.521587 [debug] [Thread-1  ]: Began compiling node test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778
[0m20:20:39.522332 [debug] [Thread-1  ]: Compiling test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778
[0m20:20:39.530108 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778"
[0m20:20:39.531224 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.531761 [debug] [Thread-1  ]: Began executing node test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778
[0m20:20:39.532215 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.533249 [debug] [Thread-1  ]: Finished running node test.dbt_demo.not_null_my_second_dbt_model_id.151b76d778
[0m20:20:39.533901 [debug] [Thread-1  ]: Began running node test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493
[0m20:20:39.534791 [debug] [Thread-1  ]: Acquiring new databricks connection "test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493"
[0m20:20:39.535177 [debug] [Thread-1  ]: Began compiling node test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493
[0m20:20:39.535586 [debug] [Thread-1  ]: Compiling test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493
[0m20:20:39.551993 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493"
[0m20:20:39.554063 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.555319 [debug] [Thread-1  ]: Began executing node test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493
[0m20:20:39.556080 [debug] [Thread-1  ]: finished collecting timing info
[0m20:20:39.558408 [debug] [Thread-1  ]: Finished running node test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493
[0m20:20:39.560442 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:20:39.561132 [debug] [MainThread]: Connection 'test.dbt_demo.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m20:20:39.578285 [info ] [MainThread]: Done.
[0m20:20:39.583316 [debug] [MainThread]: Acquiring new databricks connection "generate_catalog"
[0m20:20:39.583837 [info ] [MainThread]: Building catalog
[0m20:20:39.586174 [debug] [ThreadPool]: Acquiring new databricks connection "schema_dbt"
[0m20:20:39.602701 [info ] [MainThread]: Catalog written to /Users/tcsilva/workspace/pessoal/estudos/dbt/dbt-repos/dbt-demo/target/catalog.json
[0m20:20:39.604600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165ea040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11695a4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11695a970>]}
[0m20:20:39.606280 [debug] [MainThread]: Flushing usage events
[0m20:20:40.464806 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m20:20:40.465726 [debug] [MainThread]: Connection 'schema_dbt' was properly closed.
